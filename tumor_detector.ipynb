{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KedarPanchal/Breast-Cancer-Detector/blob/main/tumor_detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c06f7184",
      "metadata": {},
      "source": [
        "# Fine-Tuning EfficientNet-B1 for Breast Cancer Classification\n",
        "\n",
        "This notebook walks through the process of fine-tuning the EfficientNet-B1 model on the Breast Ultrasound Images Dataset (BUSI) to classify identified tumors in ultrasounds as benign or malignant.\n",
        "\n",
        "AI models such as this one act as a \"second set of eyes\" can help improve radiologist accuracy and ensure that less malignant tumors are misclassified as benign, allowing for more people to receive the treatment they need.\n",
        "\n",
        "**Dataset:** Dataset of breast ultrasound images by Walid Al-Dhabyani, Mohammed Gomma, Hussien Khaled, and Aly Fahmy.\n",
        "\n",
        "### Notebook Sections:\n",
        "1. Check Python Version and Import Dependencies\n",
        "2. Download, Preprocess, and Load Data\n",
        "3. Initialize Training and Evaluation Device and Functions\n",
        "4. Define Model Architecture and Prepare for Training\n",
        "5. Cross-Validate Model\n",
        "6. Final Model, Conclusions, and Bibliography\n",
        "\n",
        "This model was developed on an M4 MacBook Pro, 16 GB Unified RAM, 10-core CPU 10-core GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96a980a0",
      "metadata": {},
      "source": [
        "## Section 1: Check Python Version and Import Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdce3096",
      "metadata": {
        "id": "cdce3096"
      },
      "source": [
        "### Python Version\n",
        "This neural network runs on Python 3.12 to ensure compatability with its dependencies. If you are running this notebook in a virtual environment, ensure you have the correct runtime selected by running the below cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac792483",
      "metadata": {
        "id": "ac792483"
      },
      "outputs": [],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99faf28f",
      "metadata": {
        "id": "99faf28f"
      },
      "source": [
        "### Install Packages\n",
        "Install the following packages for use in the notebook:\n",
        "* **Torch:** The model is built using the PyTorch framework (this is also what limits the Python version to <= 3.12)\n",
        "* **Torchvision:** Has functions for handling and preparing datasets for PyTorch models\n",
        "* **Opendatasets:** Download datasets from the Kaggle online repository\n",
        "* **Scikit-Learn:** Use its k-fold dataset splitting functionality for k-fold cross validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6b2a6a2",
      "metadata": {
        "id": "e6b2a6a2"
      },
      "outputs": [],
      "source": [
        "%pip install torch\n",
        "%pip install torchvision\n",
        "%pip install opendatasets\n",
        "%pip install scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f775dd27",
      "metadata": {
        "id": "f775dd27"
      },
      "source": [
        "### Import Necessary Dependencies\n",
        "Import necessary dependencies for modifying and fine-tuning a pretrained model, loading and transforming data, splitting data, calculating hyperparameters, and logging information during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cee9d9a5",
      "metadata": {
        "id": "cee9d9a5"
      },
      "outputs": [],
      "source": [
        "# Model development\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "# Model training\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import copy\n",
        "import os\n",
        "\n",
        "# Data loading, transforming, and splitting\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import v2\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Logging information during training\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f316cff",
      "metadata": {},
      "source": [
        "## Section 2: Download, Preprocess, and Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b90d44b",
      "metadata": {
        "id": "4b90d44b"
      },
      "source": [
        "### Download Dataset\n",
        "> Prior to running this code block, ensure you have access to your Kaggle username and API Key, as the download will prompt you to enter this information. Visit the Kaggle website for information on how to acquire an API key.\n",
        "\n",
        "Download the breast tumor ultrasound images from Kaggle for use in training the model.\n",
        "\n",
        "The neural network uses breast cancer ultrasound data from:\n",
        "\n",
        "* The Breast Ultrasound Images (BUSI) Dataset (Al-Dhabyani W, Gomaa M, Khaled H, Fahmy A. Dataset of breast ultrasound images. Data in Brief. 2020 Feb;28:104863. DOI: 10.1016/j.dib.2019.104863.)\n",
        "\n",
        "The BUSI dataset had an additional \"normal\" class of ultrasounds that had no tumors. This class of images is deleted in this cell as the purpose of this model is to identify whether a detected tumor is malignant or benign, so a class of images with no tumor provides no value to this model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3f43d0f",
      "metadata": {
        "id": "a3f43d0f"
      },
      "outputs": [],
      "source": [
        "import opendatasets\n",
        "opendatasets.download(\"https://www.kaggle.com/datasets/aryashah2k/breast-ultrasound-images-dataset\")\n",
        "\n",
        "!mkdir data\n",
        "# Remove the normal class of ultrasounds\n",
        "!rm -rf breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/normal\n",
        "!mv breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/* data\n",
        "!rm -rf breast-ultrasound-images-dataset\n",
        "!find data -type f -name \"*_mask*.png\" -delete"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a26644a8",
      "metadata": {},
      "source": [
        "### Delete .DS_Store Files\n",
        "macOS (the platform this model was developed on) adds `.DS_Store` files to folders. Delete these as they're not needed in the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3005fb2",
      "metadata": {},
      "outputs": [],
      "source": [
        "!find . -name \".DS_Store\" -print -delete"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c5984f5",
      "metadata": {},
      "source": [
        "### Verify Mean and Standard Deviation of Dataset\n",
        "Calculate the mean and standard deviation of the dataset in order to effectively normalize the data to boost model performance. The standard deviation calculation utilizes a variation of the variance formula, where:\n",
        "$$\n",
        "\\sigma^2 = \\frac 1 n\\sum_{i=0}^{n} x_i^2 - \\mu^2\n",
        "$$\n",
        "$\\sigma^2 =$ variance, or standard deviation squared\n",
        "\n",
        "$n =$ number of data points\n",
        "\n",
        "$x_i =$ value in the data at index $i$\n",
        "\n",
        "$\\mu =$ mean of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f27657a",
      "metadata": {},
      "outputs": [],
      "source": [
        "to_tensor = v2.Compose([\n",
        "    v2.Grayscale(num_output_channels=1),\n",
        "    v2.Resize((224, 224)),\n",
        "    v2.ToImage(),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "])\n",
        "\n",
        "mean_std_dataset = ImageFolder(root=\"data\", transform=to_tensor)\n",
        "mean_std_loader = DataLoader(dataset=mean_std_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "sum = torch.tensor([0.0])\n",
        "sum_2 = torch.tensor([0.0])\n",
        "n = len(mean_std_loader)*32*(224**2)\n",
        "\n",
        "for images, _ in mean_std_loader:\n",
        "    sum += images.sum(axis=[0, 2, 3])\n",
        "    sum_2 += (images**2).sum(axis=[0, 2, 3])\n",
        "\n",
        "mean = sum/n\n",
        "std = torch.sqrt((sum_2/n - mean**2))\n",
        "\n",
        "# Should output a mean of 0.3178 and standard deviation of 0.2253\n",
        "print(f\"Mean: {mean}, Standard Deviation {std}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b3b7c54",
      "metadata": {
        "id": "7b3b7c54"
      },
      "source": [
        "### Initialize and Transform Datasets\n",
        "Load and transform images from the dataset into a more suitable format for the model.\n",
        "\n",
        "The data is turned into a labeled dataset with the following labels:\n",
        "* Images in `data/benign` will have a label `0`\n",
        "* Images in `data/malignant` will have a label `1`\n",
        "\n",
        "Images in the dataset are also transformed, depending on whether they're used for training or evaluation: \n",
        "* Training images are converted to grayscale (ultrasounds are in black and white anyway, so training on 3 color channels is a waste of compute), have various random transformations performed on them when loaded to improve model generalizability, resized to `224x224` pixels, transformed to tensors, and normalized to have a mean of 0.3178 and standard deviation of 0.2253.\n",
        "* Evaluation images are converted to grayscale, resized to `224x224` pixels, transformed to tensors, and normalized to have a mean of 0.3178 and standard deviation of 0.2253."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "176e3778",
      "metadata": {
        "id": "176e3778"
      },
      "outputs": [],
      "source": [
        "train_transform = v2.Compose([\n",
        "    v2.Grayscale(num_output_channels=1),\n",
        "    v2.RandomHorizontalFlip(0.5),\n",
        "    v2.RandomRotation(20),\n",
        "    v2.RandomAutocontrast(0.3),\n",
        "    v2.RandomAdjustSharpness(2, 0.3),\n",
        "    v2.RandomEqualize(0.2),\n",
        "\n",
        "    v2.Resize((224, 224)),\n",
        "\n",
        "    v2.ToImage(),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Normalize(mean=[0.3178], std=[0.2253])\n",
        "])\n",
        "\n",
        "test_transform = v2.Compose([\n",
        "    v2.Grayscale(num_output_channels=1),\n",
        "    v2.Resize((224, 224)),\n",
        "    v2.ToImage(),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Normalize(mean=[0.3178], std=[0.2253])\n",
        "])\n",
        "\n",
        "dataset = ImageFolder(root=\"data\", transform=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "012721b0",
      "metadata": {},
      "source": [
        "## Section 3: Initialize Training and Evaluation Device and Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "391a2eb1",
      "metadata": {
        "id": "391a2eb1"
      },
      "source": [
        "### Select Device for Training\n",
        "Select the best available device for training, testing, and performing inferences with the AI model. If a CUDA GPU is available, all calculations will be performed on the GPU. If an M-series Mac is used, PyTorch's MPS backend is used. Otherwise, all calculations will be done on the CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de716683",
      "metadata": {
        "id": "de716683"
      },
      "outputs": [],
      "source": [
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3daa1f8b",
      "metadata": {},
      "source": [
        "### Define Training Function\n",
        "Define the function used to train the model. The function logs the following:\n",
        "* The current fold if performing k-fold cross validation\n",
        "* The current epoch the model is being trained on\n",
        "* The current batch in the current epoch the model is being trained on\n",
        "* The cumulative loss across the past 10 batches\n",
        "* The time it took to train the past 10 batches\n",
        "\n",
        "The function also contains the necessary reshaping and casting to make the model's outputs compatible with the loss function used to train this model (initialized in a later cell)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b53d43ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, data_loader, optimizer, loss_fn, scheduler, current_fold=None, num_epochs=20, device=device):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        i = 0\n",
        "        start_time = time.time()\n",
        "        current_loss = 0.0\n",
        "\n",
        "        for inputs, labels in data_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs.view(-1), labels.float())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            current_loss += loss.item()\n",
        "            if i % 10 == 9 or i == len(data_loader) - 1:\n",
        "                end_time = time.time()\n",
        "                if current_fold is not None:\n",
        "                    print(f\"[Fold: {current_fold + 1}, Epoch: {epoch + 1}/{num_epochs}, Batch: {i + 1}/{len(data_loader)}] Loss: {current_loss:0.5f}, Time Elapsed: {end_time - start_time:0.5f}s\")\n",
        "                else:\n",
        "                    print(f\"[Epoch: {epoch + 1}/{num_epochs}, Batch: {i + 1}/{len(data_loader)}] Loss: {current_loss:0.5f}, Time Elapsed: {end_time - start_time:0.5f}s\")\n",
        "                current_loss = 0.0\n",
        "                start_time = end_time\n",
        "            i += 1\n",
        "\n",
        "\n",
        "    print(\"Training Complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cc5fe6f",
      "metadata": {},
      "source": [
        "### Define Evaluation Function\n",
        "Define the function utilized for evaluating the model against a certain threshold. Returns a 4-element tuple containing the classification model's accuracy, precision, recall, and F1 score (in that order)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "168c6a25",
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(model, data_loader, threshold, device=device):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    total_positive = 0\n",
        "    predicted_positive = 0\n",
        "    predicted_positive_correct = 0\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            predicted = torch.sigmoid(outputs.data)\n",
        "            predicted = (predicted > threshold).long()\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total_positive += (labels == 1).sum().item()\n",
        "            predicted_positive += (predicted == 1).sum().item()\n",
        "            predicted_positive_correct += (predicted == labels and predicted == 1).sum().item()\n",
        "\n",
        "    accuracy = correct/total\n",
        "    precision = predicted_positive_correct/predicted_positive\n",
        "    recall = predicted_positive_correct/total_positive\n",
        "    f1_score = 2 * precision * recall/(precision + recall)\n",
        "    return (accuracy, precision, recall, f1_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b733ec5",
      "metadata": {},
      "source": [
        "## Section 4: Define Model Architecture and Prepare for Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32323d5e",
      "metadata": {},
      "source": [
        "### Initialize EfficientNet-B1 Model\n",
        "Initialize the classification model.\n",
        "\n",
        "The classification model used is a fine-tuning of the EfficientNet-B1 architecture. EfficientNet-B1 was selected due to its balance between computational efficiency, performance, training time, and generalizability. The model is initialized using its pretrained weights used in classifying the ImageNet dataset (the data the original EfficientNet models were trained on) to leverage its existing knowledge as a starting point. Since ImageNet has RGB images as its data and 1000 output classes, the model's input and classification layers are modified to accept grayscale images and have a single output logit for binary classification.\n",
        "\n",
        "* The input layer is modified to accept grayscale images (1 input feature in the initial `Conv2d` layer instead of the 3 usually used when processing RGB images).\n",
        "* The final classification head is replaced with a more robust multilayer perceptron classifier that outputs a single logit: whether the input image contains a benign or malignant tumor. `SiLU` activation layers are utilized in this classification head to maintain consistency with the rest of the EfficientNet-B1 model (which uses `SiLU` consistently as an activation function), and `Dropout` layers are placed to ensure that the model does not overfit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c5a4f4d",
      "metadata": {},
      "outputs": [],
      "source": [
        "cancer_net = models.efficientnet_b1(weights=models.EfficientNet_B1_Weights.DEFAULT)\n",
        "cancer_net.features[0] = nn.Sequential(\n",
        "    nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(32),\n",
        "    nn.SiLU(inplace=True)\n",
        ")\n",
        "cancer_net.classifier = nn.Sequential(\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(cancer_net.classifier[1].in_features, 512),\n",
        "    nn.SiLU(inplace=True),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(512, 128),\n",
        "    nn.SiLU(inplace=True),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(128, 1)    \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98188913",
      "metadata": {},
      "source": [
        "### Initialize Loss, Model State Dictionary, and Number of Training Epochs\n",
        "Set up variables for use in final model training and k-fold cross-validation:\n",
        "* `num_epochs`: The number of epochs the model will be trained on during cross-validation and final training. 10 epochs were selected as it created a good balance between preventing under/overfitting the model.\n",
        "* `cancer_net`: Reinitializes the model to run on the most efficient device.\n",
        "* `loss_fn`: Uses `BCEWithLogitsLoss` to calculate the binary crossentropy loss of the model, as the model is a binary classification model whose output is a single logit.\n",
        "* `state_dict`: Saves a deep copy the default weights for the model to reinitialize to during k-fold cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51a25348",
      "metadata": {},
      "outputs": [],
      "source": [
        "num_epochs = 10\n",
        "cancer_net = cancer_net.to(device)\n",
        "loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([1.2 * len(os.listdir(\"./data/benign\"))/len(os.listdir(\"./data/malignant\"))]).to(device))\n",
        "state_dict = copy.deepcopy(cancer_net.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76f1ec5e",
      "metadata": {},
      "source": [
        "## Section 5: Cross-Validate the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd74da82",
      "metadata": {},
      "source": [
        "### Train the EfficientNet-B1 Model Using K-Fold Cross Validation\n",
        "Cross-validate the custom EfficientNet-B1 model across 5 folds, keeping track of its average accuracy, precision, recall, and F1 score across all 5 folds. \n",
        "\n",
        "During each fold, the following is done:\n",
        "* The model's optimizer and scheduler are reinitialized.\n",
        "* The training and evaluation data is split, transformed, and loaded according to the current fold.\n",
        "* The model is trained on the training data in batches of 32 images.\n",
        "* The model is evaluated on the evaluation data.\n",
        "* The model's weights are reinitialized to the default for the next fold.\n",
        "\n",
        "The model uses the `AdamW` optimizer with a weight decay of 0.0001 and a `CyclicLR` scheduler with exponential scaling and quick cycles. The `KFold` dataset splitter is initialized with a random state of 42 to ensure reproducability. When implementing this model the random state can be removed to ensure random dataset splitting. The number 42 was selected because it is the answer to life, the universe, and everything, and thus seemed to satisfy the question: \"what value should I seed my dataset splitter's randomizer to?\"\n",
        "\n",
        "The model's average performance across all folds upon training was as follows (this may differ slightly when re-run due to the random transformations performed on the training data and some random weight initializations in the modified model):\n",
        "* Accuracy: 84.5343%\n",
        "* Precision: 71.3774%\n",
        "* Recall: 88.2413%\n",
        "* F1 Score: 0.788155"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "760182b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "folds = 5\n",
        "batch_size = 32\n",
        "\n",
        "total_a, total_p, total_r, total_f1 = 0, 0, 0, 0\n",
        "\n",
        "k_fold = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
        "for fold, (train_i, test_i) in enumerate(k_fold.split(dataset)):\n",
        "    optimizer = optim.AdamW(cancer_net.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "    scheduler = lr_scheduler.CyclicLR(optimizer, base_lr=3e-4, max_lr=1e-3, step_size_up=2, mode=\"exp_range\")\n",
        "\n",
        "    train_data = Subset(dataset=dataset, indices=train_i)\n",
        "    train_data.dataset.transform = train_transform\n",
        "    train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    test_data = Subset(dataset=dataset, indices=test_i)\n",
        "    test_data.dataset.transform = test_transform\n",
        "    test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
        "\n",
        "    train_model(cancer_net, train_loader, optimizer, loss_fn, scheduler, current_fold=fold, num_epochs=num_epochs)\n",
        "    accuracy, precision, recall, f1_score = evaluate_model(cancer_net, data_loader=test_loader, threshold=0.3)\n",
        "    total_a += accuracy\n",
        "    total_p += precision\n",
        "    total_r += recall\n",
        "    total_f1 += f1_score\n",
        "\n",
        "    print(f\"Test Accuracy: {accuracy:0.7f}\")\n",
        "    print(f\"Test Precision: {precision:0.7f}\")\n",
        "    print(f\"Test Recall: {recall:0.7f}\")\n",
        "    print(f\"Test F1 Score: {f1_score:0.7f}\")\n",
        "    \n",
        "    cancer_net.load_state_dict(state_dict)\n",
        "\n",
        "print()\n",
        "print(f\"Average Accuracy: {total_a/folds:0.7f}\")\n",
        "print(f\"Average Precision: {total_p/folds:0.7f}\")\n",
        "print(f\"Average Recall: {total_r/folds:0.7f}\")\n",
        "print(f\"Average F1 Score: {total_f1/folds:0.7f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79c6d6c5",
      "metadata": {},
      "source": [
        "## Section 6: Final Model, Conclusions, and Bibliography"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6efb4130",
      "metadata": {},
      "source": [
        "### Train the Final Model\n",
        "Train the model now that the model's architecture and hyperparameters have been cross-validated. \n",
        "\n",
        "The model's weights are reinitialized to be trained on the entirety of the BUSI dataset, transformed according to the training transformations specified earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb6d791b",
      "metadata": {},
      "outputs": [],
      "source": [
        "cancer_net.load_state_dict(state_dict=state_dict)\n",
        "\n",
        "optimizer = optim.AdamW(cancer_net.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "scheduler = lr_scheduler.CyclicLR(optimizer, base_lr=3e-4, max_lr=1e-3, step_size_up=2, mode=\"exp_range\")\n",
        "\n",
        "dataset.transform = train_transform\n",
        "dataset_loader = DataLoader(dataset=dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "train_model(cancer_net, dataset_loader, optimizer, loss_fn, scheduler, None, num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8876f6c4",
      "metadata": {},
      "source": [
        "### Save the Final Model's Weights\n",
        "Save the model's weights for future inference since it has been fully trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5db0b597",
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(cancer_net.state_dict(), \"cancer_net_weights.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f316ad52",
      "metadata": {},
      "source": [
        "### Conclusion\n",
        "While the fine-tuned version of EfficientNet-B1 creates a moderately accurate classification model that balances training time and inference speed with performance. Due to this model being developed on macOS, and thus using the Metal Performance Shader backend. This backend is missing a lot of the features available to CUDA devices that improve its training speed, most notably mixed-precision training and JIT compilation, so model performance was sacrificed for reduced development time. If developed on a CUDA device, a much deeper custom architecture could be used (such as Fus2Net) without having exorbinant training and inference times.\n",
        "\n",
        "If this model were to be used in an applied setting, tumors marked as benign should also be analyzed by an experienced radiologist to ensure that false negatives don't slip through the model's 88% recall. Due to its lower accuracy, there's also a chance that the model may classify benign tumors as potentially malignant, but this is less worrysome in a medical setting as further investigation of potential false positives is always the safest move."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bc29bdc",
      "metadata": {},
      "source": [
        "### Bibliography\n",
        "* Al-Dhabyani W, et al. Dataset of breast ultrasound images. Data in Brief. 2020 Feb;28:104863. *DOI: 10.1016/j.dib.2019.104863.*\n",
        "* Ma, H., et al. Fus2Net: A Novel Convolutional Neural Network for Classification of Benign and Malignant Breast Tumor in Ultrasound Images *ResearchGate preprint DOI:10.21203/rs.3.rs-853246/v1*\n",
        "* Tan M, Le Quoc V. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks.  *arXiv:1905.11946*"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
